% Chapter 1:
% ----------
\section{Introduction}\label{chap:chap_1}


% Section 1:
%-----------
\subsection{Motivation}

Transportation nowadays has acquired a new round of development with the introduction of autonomous driving technologies based on machine learning, neural networks, and artificial intelligence. This has influenced safety, efficiency and accessibility of transportation. The key challenge of a self-driving vehicle is the number of decisions required for an algorithm to be taken in real-time, which may cause endangering consequences for drivers, passengers and other traffic participants. Reinforcement Learning is a promising approach to tackle this challenge because it allows systems to learn by trying different actions and improving over time. However, to train Reinforcement Learning sufficiently for real-world driving, it needs a lot of time and big data sets for the learning process.

The major weakness of Reinforcement Learning is the lack of adaptivity of models to new environments. This requires an additional learning process, which is time-consuming and inefficient. This is where Transfer Learning can help. It enables the ability of a system to take what it has learned in one environment and then apply this gathered knowledge to a different task, with less effort and time taken. Emphasizing the focus of Transfer Learning to be trained on critical states of the system--the moments where making the right decision matters for safety and performance--may enhance the learning speed and perform better under real-world conditions.

This thesis explores an approach to improving Reinforcement Learning's knowledge transfer in autonomous driving by applying critical situations to the models' training process. The aim is to reduce training time and computational costs while maintaining or even enhancing the performance of models, broadening the variety of challenges that could be handled, and ensuring the effectiveness of learning. By addressing these issues, this research could contribute to the further development of autonomous driving systems by making them more practical and reliable.

By experiments conducted in simulated autonomous driving environments, the thesis demonstrates the reduction of training time through applying the approach that leverages criticality-based Transfer Learning. The resultant model maintains performance, comparable to standard Transfer Learning.

% Section 2:
%-----------
\subsection{Objective}

The objective of this bachelor thesis is to research incorporating criticality-based training to enhance the efficiency of Transfer Learning. Traditional Reinforcement Learning methods require broad datasets and are computationally expensive to achieve optimal performance. Utilising Transfer Learning, pre-trained models can be leveraged in new environments, which can greatly reduce time. Despite that, standard Transfer Learning algorithms are still based on large sets of data, introducing inefficiencies.

One novel approach is introduced by this thesis: feed the pre-trained model with an exclusive set of critical states, optimising, by that, the Transfer Learning. Setting a focus on high-impact and highly informative states, the aim is to diminish training time, and costs, maintaining or even bettering the model's performance. The paper will validate the hypothesis through practical implementation, analysing performance results for both traditional Transfer Learning and criticality-aware Transfer Learning in simulated environments for autonomous driving.

% Section 3:
%-----------
\subsection{Scope}

This research is focused on the application of Reinforcement Learning in the field of autonomous driving. Specifically, the thesis is centred on evaluating the influence of Transfer Learning based on critical states inside of two environments for simulated driving:

\begin{enumerate}
 \item \textbf{Highway-Env:} An environment, where an agent has to learn to handle lane-changing and collision-avoiding situations while navigating the simplified highway simulation autonomously.
 \item \textbf{Merge-Env:} An environment, that realises more complex highway-merging scenarios, encouraging the agent to handle dynamic scenarios involving surrounding traffic.
\end{enumerate}

Deep Q-Learning (DQN) will mainly be used as a base for the implementations of Reinforcement Learning models. Resultant models will further be accessed according to their performance under various methodologies of training. Crucial model types are: 

\begin{enumerate}
 \item \textbf{Basic Reinforcement Learning Model:} A model trained using DQN purely in a single environment.
 \item \textbf{Traditional Transfer Learning Model:} A model trained with the use of a randomised set of states from a target environment based on the pre-trained model.
 \item \textbf{Criticality-Based Transfer Learning Model:} A model trained with the use of pre-selected critical states of the target environment, which tends to optimise the efficiency of learning.
\end{enumerate}

The testing in real-world scenarios of autonomous driving is not included in the scope. It is mainly centred on the implementation and effectiveness validation of the proposed algorithm.